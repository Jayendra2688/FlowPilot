1.how to do logging
import logging
logger  = logging.getLogger(__name__)
logger.INFO("HI")
logger.DEBUG("HI")
logger.WARNING("HI")

2. Task Registry Pattern (Dynamic Task Discovery)

  class TaskRegistry:
      _tasks = {}

      @classmethod
      def register(cls, task_type: str):
          def decorator(func):
              cls._tasks[task_type] = func
              return func
          return decorator

  @task_registry.register('send_sms')
  def send_sms_task(config):
      # Implementation

 Why this pattern?
  - Dynamic discovery: Add new task types without changing core code
  - Loose coupling: Workflow definition separated from task implementation
  - Plugin architecture: Each task is self-contained
 Example:
 # wokflow says next step is "send_sms" and call this execute_workflow_task.
 # execute_workflow_task find the task_func = task_registry.get_task(step.step_type)
 # and then call the task result = task_func(task_execution.input_data)


task_execution.input_data this wiil become config_data ==> send_sms_task(config_data)

3. Core Execution Engine (execute_workflow_task)

  This is the heart of our system. Every workflow step goes through this:

  @shared_task(bind=True, autoretry_for=(Exception,), retry_kwargs={'max_retries': 3})
  def execute_workflow_task(self, task_execution_id):
      # 1. Get task from database
      # 2. Mark as started
      # 3. Execute business logic
      # 4. Handle success/failure
      # 5. Trigger next steps

4.Imp decisions
# Database-Driven Execution -> 
here execute_workflow_task only need taskexecution inputdata 
but we sending task_id to the to preserve state
# Automatic Retry Logic

  if task_execution.retry_count < task_execution.step.max_retries:
      task_execution.schedule_retry()
      raise self.retry(exc=exc, countdown=delay_seconds)

    here self refers to current celery task



## VVIP

what is really happening here ->
User press on Execute button 
POST /api/workflows/patient-reg/run/
Assume that workflow and workflowsteps are already present

now we first have to cook the receipe and tell the status and statistics at last
->We need ? -> WorkflowExecution obj

Step1 : So First Create one workflowexe = WorkflowExecution.objects.create() this has workflow as foreign key

Step2:we have to cook the food and we have keep track of preparing different aspects of food
then we have to create TaskExceution
Taksexecution = TaskExecution.objects.create() this mainly has workflowexe forign key and step forigin key(workflow foreign key not req)
like this you creaate 
task1
task2
task3

then you do

->  execute_workflow_task.delay(task1.id)
     
    this will excecute taks using task registered in TaskRegistry 

    task_func = task_registry.get_task(step.step_type)
       
    result = task_func(task_execution.input_data)

    And calls

    trigger_next_steps(task1.workflowexe.id)

    Else
    it retires or mark whole woekflow and it as failed

->trigger_next_steps(workflowexe)

    this will trigger all step in an workflow which can be excuted

    and chesk if all steps are compled and mark workflow as complete


So basically whole drama is between execute_workflow_task and trigger_next_steps
